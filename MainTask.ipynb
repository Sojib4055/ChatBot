{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10836697-fe7e-4d7d-a653-43f0666f5836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: openai in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (1.3.7)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from openai) (0.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from openai) (2.11.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from anyio<4,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: openai==1.3.7 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (1.3.7)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from openai==1.3.7) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from openai==1.3.7) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from openai==1.3.7) (0.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from openai==1.3.7) (2.11.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from openai==1.3.7) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from openai==1.3.7) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from openai==1.3.7) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from anyio<4,>=3.5.0->openai==1.3.7) (3.7)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from anyio<4,>=3.5.0->openai==1.3.7) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.3.7) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.3.7) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.3.7) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.3.7) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.3.7) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.3.7) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from tqdm>4->openai==1.3.7) (0.4.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: selenium==4.15.2 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (4.15.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium==4.15.2) (2.3.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from selenium==4.15.2) (0.30.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from selenium==4.15.2) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from selenium==4.15.2) (2025.4.26)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from trio~=0.17->selenium==4.15.2) (24.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from trio~=0.17->selenium==4.15.2) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from trio~=0.17->selenium==4.15.2) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from trio~=0.17->selenium==4.15.2) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from trio~=0.17->selenium==4.15.2) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from trio~=0.17->selenium==4.15.2) (1.17.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from trio~=0.17->selenium==4.15.2) (1.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from trio-websocket~=0.9->selenium==4.15.2) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium==4.15.2) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium==4.15.2) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium==4.15.2) (0.16.0)\n",
      "Requirement already satisfied: groq in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (0.26.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from groq) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from groq) (0.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from groq) (2.11.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from groq) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from groq) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\user\\.conda\\envs\\chatboot\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn openai\n",
    "!pip install openai==1.3.7\n",
    "!pip install pandas scikit-learn\n",
    "!pip install selenium==4.15.2\n",
    "!pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63043eee-6ab4-4476-bd73-4282fe530e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌐 Opened website, waiting for table to load...\n",
      "✅ Data saved to worldometers_covid1.csv\n",
      "🚪 Browser closed.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Setup Chrome options (visible browser)\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "\n",
    "# Set your correct ChromeDriver path\n",
    "service = Service(r\"C:\\Users\\UseR\\Intern Task\\Task\\chromedriver-win64\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "try:\n",
    "    # Open the Worldometer page\n",
    "    driver.get(\"https://www.worldometers.info/coronavirus/\")\n",
    "    print(\"🌐 Opened website, waiting for table to load...\")\n",
    "\n",
    "    # Wait for table to fully load\n",
    "    WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.ID, \"main_table_countries_today\"))\n",
    "    )\n",
    "\n",
    "    time.sleep(5)  # Extra wait for JS-rendered content\n",
    "\n",
    "    # Scrape the table\n",
    "    table = driver.find_element(By.ID, \"main_table_countries_today\")\n",
    "    rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        # Skip rows with style=\"display: none\" (continent totals)\n",
    "        if \"display: none\" not in row.get_attribute(\"style\"):\n",
    "            cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "            if len(cols) >= 9:  # Ensure row has enough columns\n",
    "                data.append({\n",
    "                    \"Rank\": cols[0].text.strip(),\n",
    "                    \"Country\": cols[1].text.strip(),\n",
    "                    \"Total Cases\": cols[2].text.strip(),\n",
    "                    \"Total Deaths\": cols[3].text.strip(),\n",
    "                    \"Total Recovered\": cols[4].text.strip(),\n",
    "                    \"Tot Cases/1M pop\": cols[5].text.strip(),\n",
    "                    \"Deaths/1M pop\": cols[6].text.strip(),\n",
    "                    \"Population\": cols[7].text.strip(),\n",
    "                    \"Continent\": cols[8].text.strip()\n",
    "                })\n",
    "\n",
    "    # Save data to CSV safely\n",
    "    filename = \"worldometers_covid1.csv\"\n",
    "    if os.path.exists(filename):\n",
    "        try:\n",
    "            os.remove(filename)\n",
    "        except:\n",
    "            print(f\"⚠️ File '{filename}' is open. Please close it and rerun.\")\n",
    "            driver.quit()\n",
    "            exit()\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(filename, index=False, encoding='utf-8')\n",
    "    print(f\"✅ Data saved to {filename}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n",
    "    print(\"🚪 Browser closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a86258-8ff4-4358-8540-103b61be0576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Chatbot for COVID-19 Data (type 'exit' to quit)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from groq import Groq\n",
    "import re\n",
    "from typing import List, Dict\n",
    "\n",
    "# Initialize Groq client\n",
    "client = Groq(api_key=\"api_key\")  # Replace with your Groq API key\n",
    "\n",
    "# Load and preprocess CSV data\n",
    "def load_and_preprocess_data(file_path: str = \"worldometers_covid1.csv\") -> pd.DataFrame:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"CSV file '{file_path}' not found. Please run the scraper first.\")\n",
    "\n",
    "    # Verify required columns\n",
    "    expected_columns = [\"Rank\", \"Country\", \"Total Cases\", \"Total Deaths\", \"Total Recovered\", \"Tot Cases/1M pop\", \"Deaths/1M pop\", \"Population\", \"Continent\"]\n",
    "    missing_columns = [col for col in expected_columns if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        raise KeyError(f\"Missing required columns in CSV: {missing_columns}\")\n",
    "\n",
    "    # Clean numerical columns\n",
    "    numerical_columns = [\"Total Cases\", \"Total Deaths\", \"Total Recovered\", \"Tot Cases/1M pop\", \"Deaths/1M pop\", \"Population\"]\n",
    "    for col in numerical_columns:\n",
    "        df[col] = df[col].replace({\",\": \"\", \"N/A\": None}, regex=True).astype(float, errors=\"ignore\")\n",
    "\n",
    "    # Create search-friendly country names\n",
    "    df[\"search_country\"] = df[\"Country\"].str.lower().replace({\n",
    "        \"us\": \"usa\", \"united states\": \"usa\", \"uk\": \"united kingdom\",\n",
    "        \"south korea\": \"s. korea\", \"north korea\": \"dprk\"\n",
    "    })\n",
    "\n",
    "    # Create combined_text for vectorization, weighting Country higher\n",
    "    df[\"combined_text\"] = df.apply(\n",
    "        lambda row: f\"{row['Country']} {row['Country']} {row['Country']} | {row['Continent']} | \" +\n",
    "        \" | \".join(str(v) for v in row[[\"Rank\", \"Total Cases\", \"Total Deaths\", \"Total Recovered\", \"Tot Cases/1M pop\", \"Deaths/1M pop\", \"Population\"]]),\n",
    "        axis=1\n",
    "    )\n",
    "    return df\n",
    "\n",
    "try:\n",
    "    df = load_and_preprocess_data()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {str(e)}\")\n",
    "    exit()\n",
    "\n",
    "# Enhanced retrieval function\n",
    "def retrieve_top_k(query: str, k: int = 5) -> List[Dict]:\n",
    "    query_lower = query.lower()\n",
    "\n",
    "    # Query analysis\n",
    "    continents = [\"europe\", \"north america\", \"asia\", \"south america\", \"africa\", \"australia/oceania\"]\n",
    "    is_continent_query = any(cont in query_lower for cont in continents)\n",
    "    is_world_query = \"world\" in query_lower\n",
    "    is_comparison = any(word in query_lower for word in [\"highest\", \"lowest\", \"most\", \"least\", \"top\", \"compare\"])\n",
    "    country_matches = [c for c in df[\"search_country\"].unique() if c in query_lower]\n",
    "\n",
    "    # Filter dataframe based on query intent\n",
    "    if is_world_query:\n",
    "        df_subset = df[df[\"Country\"].str.lower() == \"world\"]\n",
    "    elif is_continent_query:\n",
    "        continent_name = next((c for c in continents if c in query_lower), None)\n",
    "        if continent_name:\n",
    "            # Map query continent to CSV continent\n",
    "            continent_name = \"Australia/Oceania\" if continent_name == \"australia/oceania\" or continent_name == \"oceania\" else continent_name.title()\n",
    "            df_subset = df[df[\"Continent\"] == continent_name]\n",
    "        else:\n",
    "            df_subset = df\n",
    "        if country_matches:\n",
    "            df_subset = df_subset[df_subset[\"search_country\"].isin(country_matches)]\n",
    "    elif country_matches:\n",
    "        df_subset = df[df[\"search_country\"].isin(country_matches)]\n",
    "    else:\n",
    "        df_subset = df[df[\"Country\"] != \"World\"]  # Exclude World for general queries\n",
    "\n",
    "    if df_subset.empty:\n",
    "        return []\n",
    "\n",
    "    # Vectorize with focus on relevant fields\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    matrix = vectorizer.fit_transform(df_subset[\"combined_text\"].tolist() + [query])\n",
    "    similarity = cosine_similarity(matrix[-1], matrix[:-1]).flatten()\n",
    "    top_indices = similarity.argsort()[-k:][::-1]\n",
    "\n",
    "    # Sort for comparison queries\n",
    "    if is_comparison:\n",
    "        if \"cases\" in query_lower:\n",
    "            top_indices = df_subset.iloc[top_indices].sort_values(\"Total Cases\", ascending=False).index\n",
    "        elif \"deaths\" in query_lower:\n",
    "            top_indices = df_subset.iloc[top_indices].sort_values(\"Total Deaths\", ascending=False).index\n",
    "        elif \"deaths/1m\" in query_lower or \"deaths per million\" in query_lower:\n",
    "            top_indices = df_subset.iloc[top_indices].sort_values(\"Deaths/1M pop\", ascending=False).index\n",
    "\n",
    "    # Return top-k records\n",
    "    return df_subset.iloc[top_indices][[\"Rank\", \"Country\", \"Total Cases\", \"Total Deaths\", \"Total Recovered\", \"Tot Cases/1M pop\", \"Deaths/1M pop\", \"Population\", \"Continent\"]].to_dict(\"records\")\n",
    "\n",
    "# RAG query function\n",
    "def rag_query(question: str, context_list: List[Dict]) -> str:\n",
    "    if not question:\n",
    "        return \"Please enter a valid question.\"\n",
    "\n",
    "    if not context_list:\n",
    "        return \"Sorry, I couldn't find relevant data to answer your question. Try specifying a country or continent.\"\n",
    "\n",
    "    # Define context string\n",
    "    context = \"Data (Country | Continent | Total Cases | Total Deaths | Total Recovered | Total Cases/1M Pop | Deaths/1M Pop | Population):\\n\"\n",
    "    for item in context_list:\n",
    "        context += f\"{item['Country']} | {item['Continent']} | {item['Total Cases']:,} | {item['Total Deaths']:,} | {item['Total Recovered']:,} | {item['Tot Cases/1M pop']:,} | {item['Deaths/1M pop']:,} | {item['Population']:,}\\n\"\n",
    "\n",
    "    # Optimized prompt for RAG\n",
    "    prompt = f\"\"\"You are an expert assistant answering questions about COVID-19 data using only the provided dataset. Follow these rules:\n",
    "- Answer concisely and precisely, using exact numbers formatted with commas (e.g., 1,234,567).\n",
    "- For comparisons (e.g., 'highest', 'top'), rank the data and provide the top result(s) with values.\n",
    "- For 'compare' queries, list metrics side by side.\n",
    "- If a value is None, state 'Data unavailable'.\n",
    "- For continent queries, note that only country-level data is available. Aggregate data for countries in the specified continent if needed, or state if aggregation is not possible.\n",
    "- If the question is unanswerable, state: 'This question cannot be answered with the provided data.'\n",
    "- Do not speculate or use external information.\n",
    "\n",
    "Examples:\n",
    "Q: Total cases in USA?\n",
    "A: The USA has 111,820,082 total COVID-19 cases.\n",
    "\n",
    "Q: Which country has the highest cases?\n",
    "A: The USA has the highest total cases with 111,820,082.\n",
    "\n",
    "Q: Compare deaths in USA and India.\n",
    "A: USA: 1,219,487 deaths | India: 533,570 deaths.\n",
    "\n",
    "Q: Total cases in Europe?\n",
    "A: The total COVID-19 cases in Europe cannot be directly calculated from country-level data alone, as continent totals are not provided. Please specify a country or another metric.\n",
    "\n",
    "Q: Cases in Narnia?\n",
    "A: This question cannot be answered with the provided data.\n",
    "\n",
    "Data:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"llama3-70b-8192\",  # More powerful model for precision\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=250,\n",
    "            temperature=0.3  # Lower temperature for factual responses\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error generating response: {str(e)}\"\n",
    "\n",
    "# RAG chatbot\n",
    "def rag_chatbot(verbose: bool = False):\n",
    "    print(\"RAG Chatbot for COVID-19 Data (type 'exit' to quit)\")\n",
    "    while True:\n",
    "        user_question = input(\"You: \").strip()\n",
    "        if user_question.lower() == \"exit\":\n",
    "            break\n",
    "        if not user_question:\n",
    "            print(\"Bot: Please enter a valid question.\")\n",
    "            continue\n",
    "\n",
    "        # Retrieve context\n",
    "        relevant_context = retrieve_top_k(user_question)\n",
    "        if not relevant_context:\n",
    "            print(\"Bot: No relevant data found. Try specifying a country, continent, or metric (e.g., cases, deaths).\")\n",
    "            continue\n",
    "\n",
    "        # Verbose output\n",
    "        if verbose:\n",
    "            print(\"Debug: Retrieved context:\")\n",
    "            for item in relevant_context:\n",
    "                print({k: f\"{v:,}\" if isinstance(v, float) else v for k, v in item.items()})\n",
    "\n",
    "        # Generate response\n",
    "        response = rag_query(user_question, relevant_context)\n",
    "        print(\"Answer:\", response)\n",
    "\n",
    "# Run the chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    rag_chatbot(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28568cb1-0661-4711-bf97-61e5e069d125",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
